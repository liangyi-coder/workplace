{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Experiment Description: 复现黄军豪在2020年发表的关于BCMS的论文中的深度学习模型\n",
    "DATA：本地医院的数据\n",
    "'''\n",
    "import tensorflow as tf \n",
    "import os\n",
    "from tensorflow.keras import layers, Sequential\n",
    "batch_size = 200\n",
    "learning_rate = 1e-3\n",
    "class_names = ['Her2', 'luminal_A', 'luminal_B', 'TN']#每个分类的名称"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "189 125 148 121\n"
     ]
    }
   ],
   "source": [
    "#获取train data文件路径\n",
    "train_data_dir = '/media/ly/liangyi/研究课题——乳腺癌分子分型分类/Data/MRI_minbox/train/'\n",
    "Her2_train_dir = train_data_dir + 'Her_2/'\n",
    "luminal_A_train_dir = train_data_dir + 'luminal_A/'\n",
    "luminal_B_train_dir = train_data_dir + 'luminal_B/'\n",
    "TN_train_dir = train_data_dir + 'TN/'\n",
    "\n",
    "Her2_train_names = [Her2_train_dir + filename for filename in os.listdir(Her2_train_dir)]\n",
    "luminal_A_train_names = [luminal_A_train_dir + filename for filename in os.listdir(luminal_A_train_dir)]\n",
    "luminal_B_train_names = [luminal_B_train_dir + filename for filename in os.listdir(luminal_B_train_dir)]\n",
    "TN_train_names = [TN_train_dir + filename for filename in os.listdir(TN_train_dir)]\n",
    "#训练集中各个分型的数量\n",
    "num_Her2_train = len(Her2_train_names)\n",
    "num_luminal_A_train = len(luminal_A_train_names)\n",
    "num_luminal_B_train = len(luminal_B_train_names)\n",
    "num_TN_train = len(TN_train_names)\n",
    "\n",
    "print(num_Her2_train, num_luminal_A_train, num_luminal_B_train, num_TN_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_names = Her2_train_names + luminal_A_train_names + luminal_B_train_names + TN_train_names\n",
    "train_labels = [0] * num_Her2_train + [1] * num_luminal_A_train + [2] * num_luminal_B_train + [3] * num_TN_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#map\n",
    "def _map_loadImage(imagename, label):\n",
    "    image_string = tf.io.read_file(imagename)\n",
    "    image_decoded = tf.image.decode_png(image_string, channels=3)\n",
    "    image_resized = tf.image.resize(image_decoded, [32,32])/255.0\n",
    "    label = tf.cast(label, dtype=tf.int32)\n",
    "    return image_resized, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_image_names, train_labels))\n",
    "train_dataset = train_dataset.map(\n",
    "    map_func=_map_loadImage,\n",
    "    num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
    ")\n",
    "train_dataset = train_dataset.shuffle(1000).batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<PrefetchDataset shapes: ((None, 32, 32, 3), (None,)), types: (tf.float32, tf.int32)>\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "81 54 63 52\n"
     ]
    }
   ],
   "source": [
    "#准备验证集\n",
    "val_data_dir = '/media/ly/liangyi/研究课题——乳腺癌分子分型分类/Data/MRI_minbox/validation/'\n",
    "Her2_val_dir = val_data_dir + 'Her_2/'\n",
    "luminal_A_val_dir = val_data_dir + 'luminal_A/'\n",
    "luminal_B_val_dir = val_data_dir + 'luminal_B/'\n",
    "TN_val_dir = val_data_dir + 'TN/'\n",
    "\n",
    "Her2_val_names = [Her2_val_dir + imagename for imagename in os.listdir(Her2_val_dir)]\n",
    "luminal_A_val_names = [luminal_A_val_dir + imagename for imagename in os.listdir(luminal_A_val_dir)]\n",
    "luminal_B_val_names = [luminal_B_val_dir + imagename for imagename in os.listdir(luminal_B_val_dir)]\n",
    "TN_val_names = [TN_val_dir + imagename for imagename in os.listdir(TN_val_dir)]\n",
    "\n",
    "num_Her2_val = len(Her2_val_names)\n",
    "num_luminal_A_val = len(luminal_A_val_names)\n",
    "num_luminal_B_val = len(luminal_B_val_names)\n",
    "num_TN_val = len(TN_val_names)\n",
    "\n",
    "print(num_Her2_val, num_luminal_A_val, num_luminal_B_val, num_TN_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_image_names = Her2_val_names + luminal_A_val_names + luminal_B_val_names + TN_val_names\n",
    "val_labels = [0] * num_Her2_val + [1] * num_luminal_A_val + [2] * num_luminal_B_val + [3] * num_TN_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "250 250\n"
     ]
    }
   ],
   "source": [
    "print(len(val_image_names), len(val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_image_names, val_labels))\n",
    "val_dataset = val_dataset.map(_map_loadImage).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<BatchDataset shapes: ((None, 32, 32, 3), (None,)), types: (tf.float32, tf.int32)>\n"
     ]
    }
   ],
   "source": [
    "print(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base = Sequential([\n",
    "    #unit1\n",
    "    layers.Conv2D(64, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu ),\n",
    "    layers.Conv2D(64, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu ),\n",
    "    layers.MaxPooling2D( pool_size=[2, 2], strides=2, padding=\"same\"),\n",
    "\n",
    "    #unit2\n",
    "    layers.Conv2D(128, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu ),\n",
    "    layers.Conv2D(128, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu ),\n",
    "    layers.MaxPooling2D( pool_size=[2, 2], strides=2, padding=\"same\"),\n",
    "\n",
    "    #unit3\n",
    "    layers.Conv2D(256, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu ),\n",
    "    layers.Conv2D(256, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu ),\n",
    "    layers.MaxPooling2D( pool_size=[2, 2], strides=2, padding=\"same\"),\n",
    "\n",
    "    #unit4\n",
    "    layers.Conv2D(512, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu ),\n",
    "    layers.Conv2D(512, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu ),\n",
    "    layers.MaxPooling2D( pool_size=[2, 2], strides=2, padding=\"same\"),\n",
    "\n",
    "    #unit5\n",
    "    layers.Conv2D(512, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu ),\n",
    "    layers.Conv2D(512, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu ),\n",
    "    layers.MaxPooling2D( pool_size=[2, 2], strides=2, padding=\"same\"),\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d (Conv2D)              (None, 32, 32, 64)        1792      \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 32, 32, 64)        36928     \n_________________________________________________________________\nmax_pooling2d (MaxPooling2D) (None, 16, 16, 64)        0         \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 16, 16, 128)       73856     \n_________________________________________________________________\nconv2d_3 (Conv2D)            (None, 16, 16, 128)       147584    \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 8, 8, 128)         0         \n_________________________________________________________________\nconv2d_4 (Conv2D)            (None, 8, 8, 256)         295168    \n_________________________________________________________________\nconv2d_5 (Conv2D)            (None, 8, 8, 256)         590080    \n_________________________________________________________________\nmax_pooling2d_2 (MaxPooling2 (None, 4, 4, 256)         0         \n_________________________________________________________________\nconv2d_6 (Conv2D)            (None, 4, 4, 512)         1180160   \n_________________________________________________________________\nconv2d_7 (Conv2D)            (None, 4, 4, 512)         2359808   \n_________________________________________________________________\nmax_pooling2d_3 (MaxPooling2 (None, 2, 2, 512)         0         \n_________________________________________________________________\nconv2d_8 (Conv2D)            (None, 2, 2, 512)         2359808   \n_________________________________________________________________\nconv2d_9 (Conv2D)            (None, 2, 2, 512)         2359808   \n_________________________________________________________________\nmax_pooling2d_4 (MaxPooling2 (None, 1, 1, 512)         0         \n=================================================================\nTotal params: 9,404,992\nTrainable params: 9,404,992\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_base.build(input_shape = [None, 32, 32, 3])\n",
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.random.normal([4,32,32,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(4, 1, 1, 512)\n"
     ]
    }
   ],
   "source": [
    "out = conv_base(x)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(4, 512)\n"
     ]
    }
   ],
   "source": [
    "out = tf.squeeze(out)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#构建全连接层\n",
    "fc_net = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(256, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(64, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(4, activation=tf.nn.relu)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_net.build(input_shape=[None, 512])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = conv_base.trainable_variables + fc_net.trainable_variables\n",
    "optimizer = tf.keras.optimizers.Adam(lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0 0 loss:  0.6933338046073914\n",
      "0 1 loss:  0.693194568157196\n",
      "0 2 loss:  0.6931471824645996\n",
      "0 acc:  0.324\n",
      "1 0 loss:  0.6931471824645996\n",
      "1 1 loss:  0.6931471824645996\n",
      "1 2 loss:  0.6939392685890198\n",
      "1 acc:  0.324\n",
      "2 0 loss:  0.6931471824645996\n",
      "2 1 loss:  0.6931471824645996\n",
      "2 2 loss:  0.6931471824645996\n",
      "2 acc:  0.324\n",
      "3 0 loss:  0.6931471824645996\n",
      "3 1 loss:  0.6931471824645996\n",
      "3 2 loss:  0.6931471824645996\n",
      "3 acc:  0.324\n",
      "4 0 loss:  0.6931471824645996\n",
      "4 1 loss:  0.6931471824645996\n",
      "4 2 loss:  0.6931471824645996\n",
      "4 acc:  0.324\n",
      "5 0 loss:  0.6931471824645996\n",
      "5 1 loss:  0.6931471824645996\n",
      "5 2 loss:  0.6931471824645996\n",
      "5 acc:  0.324\n",
      "6 0 loss:  0.6931471824645996\n",
      "6 1 loss:  0.6931471824645996\n",
      "6 2 loss:  0.6931471824645996\n",
      "6 acc:  0.324\n",
      "7 0 loss:  0.6931471824645996\n",
      "7 1 loss:  0.6931471824645996\n",
      "7 2 loss:  0.6931471824645996\n",
      "7 acc:  0.324\n",
      "8 0 loss:  0.6931471824645996\n",
      "8 1 loss:  0.6931471824645996\n",
      "8 2 loss:  0.6931471824645996\n",
      "8 acc:  0.324\n",
      "9 0 loss:  0.6931471824645996\n",
      "9 1 loss:  0.6931471824645996\n",
      "9 2 loss:  0.6931471824645996\n",
      "9 acc:  0.324\n",
      "10 0 loss:  0.6931471824645996\n",
      "10 1 loss:  0.6931471824645996\n",
      "10 2 loss:  0.6931471824645996\n",
      "10 acc:  0.324\n",
      "11 0 loss:  0.6931471824645996\n",
      "11 1 loss:  0.6931471824645996\n",
      "11 2 loss:  0.6931471824645996\n",
      "11 acc:  0.324\n",
      "12 0 loss:  0.6931471824645996\n",
      "12 1 loss:  0.6931471824645996\n",
      "12 2 loss:  0.6931471824645996\n",
      "12 acc:  0.324\n",
      "13 0 loss:  0.6931471824645996\n",
      "13 1 loss:  0.6931471824645996\n",
      "13 2 loss:  0.6931471824645996\n",
      "13 acc:  0.324\n",
      "14 0 loss:  0.6931471824645996\n",
      "14 1 loss:  0.6931471824645996\n",
      "14 2 loss:  0.6931471824645996\n",
      "14 acc:  0.324\n",
      "15 0 loss:  0.6931471824645996\n",
      "15 1 loss:  0.6931471824645996\n",
      "15 2 loss:  0.6931471824645996\n",
      "15 acc:  0.324\n",
      "16 0 loss:  0.6931471824645996\n",
      "16 1 loss:  0.6931471824645996\n",
      "16 2 loss:  0.6931471824645996\n",
      "16 acc:  0.324\n",
      "17 0 loss:  0.6931471824645996\n",
      "17 1 loss:  0.6931471824645996\n",
      "17 2 loss:  0.6931471824645996\n",
      "17 acc:  0.324\n",
      "18 0 loss:  0.6931471824645996\n",
      "18 1 loss:  0.6931471824645996\n",
      "18 2 loss:  0.6931471824645996\n",
      "18 acc:  0.324\n",
      "19 0 loss:  0.6931471824645996\n",
      "19 1 loss:  0.6931471824645996\n",
      "19 2 loss:  0.6931471824645996\n",
      "19 acc:  0.324\n",
      "20 0 loss:  0.6931471824645996\n",
      "20 1 loss:  0.6931471824645996\n",
      "20 2 loss:  0.6931471824645996\n",
      "20 acc:  0.324\n",
      "21 0 loss:  0.6931471824645996\n",
      "21 1 loss:  0.6931471824645996\n",
      "21 2 loss:  0.6931471824645996\n",
      "21 acc:  0.324\n",
      "22 0 loss:  0.6931471824645996\n",
      "22 1 loss:  0.6931471824645996\n",
      "22 2 loss:  0.6931471824645996\n",
      "22 acc:  0.324\n",
      "23 0 loss:  0.6931471824645996\n",
      "23 1 loss:  0.6931471824645996\n",
      "23 2 loss:  0.6931471824645996\n",
      "23 acc:  0.324\n",
      "24 0 loss:  0.6931471824645996\n",
      "24 1 loss:  0.6931471824645996\n",
      "24 2 loss:  0.6931471824645996\n",
      "24 acc:  0.324\n",
      "25 0 loss:  0.6931471824645996\n",
      "25 1 loss:  0.6931471824645996\n",
      "25 2 loss:  0.6931471824645996\n",
      "25 acc:  0.324\n",
      "26 0 loss:  0.6931471824645996\n",
      "26 1 loss:  0.6931471824645996\n",
      "26 2 loss:  0.6931471824645996\n",
      "26 acc:  0.324\n",
      "27 0 loss:  0.6931471824645996\n",
      "27 1 loss:  0.6931471824645996\n",
      "27 2 loss:  0.6931471824645996\n",
      "27 acc:  0.324\n",
      "28 0 loss:  0.6931471824645996\n",
      "28 1 loss:  0.6931471824645996\n",
      "28 2 loss:  0.6931471824645996\n",
      "28 acc:  0.324\n",
      "29 0 loss:  0.6931471824645996\n",
      "29 1 loss:  0.6931471824645996\n",
      "29 2 loss:  0.6931471824645996\n",
      "29 acc:  0.324\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(30):\n",
    "    for step, (x, y) in enumerate(train_dataset):\n",
    "        with tf.GradientTape() as tape:\n",
    "            # [None, 32, 32, 3] --> [None, 1, 1, 512]\n",
    "            out = conv_base(x)\n",
    "            # [None, 1, 1, 512] --> [None, 512]\n",
    "            out = tf.squeeze(out)\n",
    "            # [None, 512] --> [None, 4]\n",
    "            logits = fc_net(out)\n",
    "            #comput loss\n",
    "            y_onehot = tf.one_hot(y, depth=4)\n",
    "            loss = tf.losses.binary_crossentropy(y_onehot, logits, from_logits=True)\n",
    "            loss = tf.reduce_mean(loss)\n",
    "        grads = tape.gradient(loss, variables)\n",
    "        optimizer.apply_gradients(zip(grads, variabels))\n",
    "        print(epoch, step, 'loss: ', float(loss))\n",
    "    total_num = 0\n",
    "    total_correct = 0\n",
    "    for x, y in val_dataset:\n",
    "        out = conv_base(x)\n",
    "        out = tf.squeeze(out)\n",
    "        logits = fc_net(out)\n",
    "        prob = tf.nn.softmax(logits)\n",
    "        pred = tf.argmax(prob, axis=1)\n",
    "        pred = tf.cast(pred, dtype = tf.int32)\n",
    "\n",
    "        correct = tf.cast(tf.equal(pred, y), dtype = tf.int32)\n",
    "\n",
    "        correct = tf.reduce_sum(correct)\n",
    "        total_num += x.shape[0]\n",
    "        total_correct += int(correct)\n",
    "\n",
    "    acc = total_correct/total_num\n",
    "    print(epoch, 'acc: ',acc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python379jvsc74a57bd03110ea37ffd25c4a84d6943605b7c0ed3a62606047d22cee2356eefcf32f74cc",
   "display_name": "Python 3.7.9 64-bit ('tensorflow2.3.1': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}