{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd0b10a0342820880539ff0a4d8dcf87b4fe85065194b0b53a2e597b603be69ca3f",
   "display_name": "Python 3.8.8 64-bit ('pytorch': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ../CIFAR_10_zhuanzhi/cifar10/cifar-10-python.tar.gz\n",
      "99.9%Epoch:1, Training Loss:2.2985000215518245, Valid Loss:2.2910072922706606\n",
      "Epoch:2, Training Loss:2.2489694501184356, Valid Loss:2.2077960729599\n",
      "Epoch:3, Training Loss:2.1494046958388795, Valid Loss:2.082637870311737\n",
      "Epoch:4, Training Loss:2.0194268036799827, Valid Loss:1.9859351813793182\n",
      "Epoch:5, Training Loss:1.9337035827575975, Valid Loss:1.9302497208118439\n",
      "Epoch:6, Training Loss:1.7170442160527417, Valid Loss:1.6324455380439757\n",
      "Epoch:7, Training Loss:1.4136005564100425, Valid Loss:1.3051441311836243\n",
      "Epoch:8, Training Loss:1.2209110229637972, Valid Loss:1.254625630378723\n",
      "Epoch:9, Training Loss:1.1193555513764644, Valid Loss:1.124283641576767\n",
      "Epoch:10, Training Loss:1.0345466789925934, Valid Loss:1.1381803452968597\n",
      "Epoch:11, Training Loss:0.9590154776147976, Valid Loss:1.2034703373908997\n",
      "Epoch:12, Training Loss:0.8914053652696549, Valid Loss:1.0531902819871903\n",
      "Epoch:13, Training Loss:0.832634741713287, Valid Loss:1.0272102445363998\n",
      "Epoch:14, Training Loss:0.7785822673208395, Valid Loss:1.1230638295412063\n",
      "Epoch:15, Training Loss:0.7200837830069718, Valid Loss:0.9447486996650696\n",
      "Epoch:16, Training Loss:0.6632542236215749, Valid Loss:0.9873195230960846\n",
      "Epoch:17, Training Loss:0.6110508903196663, Valid Loss:0.879591652750969\n",
      "Epoch:18, Training Loss:0.5565395081878468, Valid Loss:0.9179434567689896\n",
      "Epoch:19, Training Loss:0.5059557076852033, Valid Loss:0.9323235660791397\n",
      "Epoch:20, Training Loss:0.4557085020147311, Valid Loss:0.9376928448677063\n",
      "Epoch:21, Training Loss:0.40714266345759104, Valid Loss:1.1885709404945373\n",
      "Epoch:22, Training Loss:0.35484134904138603, Valid Loss:1.0076320260763167\n",
      "Epoch:23, Training Loss:0.303896873430082, Valid Loss:0.996141716837883\n",
      "Epoch:24, Training Loss:0.25636169931311514, Valid Loss:1.1366609662771225\n",
      "Epoch:25, Training Loss:0.20894291826114533, Valid Loss:1.2267606377601623\n",
      "Epoch:26, Training Loss:0.17342057752950935, Valid Loss:1.3031874656677247\n",
      "Epoch:27, Training Loss:0.14112269688563742, Valid Loss:1.3592706203460694\n",
      "Epoch:28, Training Loss:0.11105016495581645, Valid Loss:1.5418386340141297\n",
      "Epoch:29, Training Loss:0.1016672404281273, Valid Loss:1.5598398685455321\n",
      "Epoch:30, Training Loss:0.08773252695419226, Valid Loss:1.5311921179294585\n",
      "======= Training Finished ! =========\n",
      "Testing Begining ... \n",
      "Accuracy : 0.7118 %\n"
     ]
    }
   ],
   "source": [
    "# coding = utf-8\n",
    "\n",
    "import torch\n",
    "import torch.nn\n",
    "import numpy as np\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optimizer\n",
    "\n",
    "\n",
    "'''\n",
    "The compose function allows for multiple transforms.\n",
    "transform.ToTensor() converts our PILImage to a tensor of \n",
    "shape (C x H x W) in the range [0, 1]\n",
    "transform.Normalize(mean, std) normalizes a tensor to a (mean, std) \n",
    "for (R, G, B)\n",
    "'''\n",
    "_task = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "# 注意：此处数据集在本地，因此download=False;若需要下载的改为True\n",
    "# 同样的，第一个参数为数据存放路径\n",
    "data_path = '../CIFAR_10_zhuanzhi/cifar10'\n",
    "cifar = CIFAR10(data_path, train=True, download=True, transform=_task)\n",
    "\n",
    "# 这里只是为了构造取样的角标，可根据自己的思路进行拓展\n",
    "# 此处使用了前百分之八十作为训练集，百分之八十到九十的作为验证集，后百分之十为测试集\n",
    "samples_count = len(cifar)\n",
    "split_train = int(0.8 * samples_count)\n",
    "split_valid = int(0.9 * samples_count)\n",
    "\n",
    "index_list = list(range(samples_count))\n",
    "train_idx, valid_idx, test_idx = index_list[:split_train], index_list[split_train:split_valid], index_list[split_valid:]\n",
    "\n",
    "# 定义采样器\n",
    "# create training and validation, test sampler\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "test_samlper  = SubsetRandomSampler(test_idx )\n",
    "\n",
    "# create iterator for train and valid, test dataset\n",
    "trainloader = DataLoader(cifar, batch_size=256, sampler=train_sampler)\n",
    "validloader = DataLoader(cifar, batch_size=256, sampler=valid_sampler)\n",
    "testloader  = DataLoader(cifar, batch_size=256, sampler=test_samlper )\n",
    "\n",
    "# 网络设计\n",
    "class Net(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    网络设计了三个卷积层，一个池化层，一个全连接层\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.conv1 = torch.nn.Conv2d(3, 16, 3, padding=1)\n",
    "        self.conv2 = torch.nn.Conv2d(16, 32, 3, padding=1)\n",
    "        self.conv3 = torch.nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.pool = torch.nn.MaxPool2d(2, 2)\n",
    "        self.linear1 = torch.nn.Linear(1024, 512)\n",
    "        self.linear2 = torch.nn.Linear(512, 10)\n",
    "    \n",
    "    # 前向传播\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 1024)\n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = F.relu(self.linear2(x))\n",
    "\n",
    "        return x\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    net = Net()  # 实例化网络\n",
    "    loss_function = torch.nn.CrossEntropyLoss()  # 定义交叉熵损失\n",
    "    \n",
    "    # 定义优化算法\n",
    "    optimizer = optimizer.SGD(net.parameters(), lr=0.01, weight_decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    \n",
    "    # 迭代次数\n",
    "    for epoch in range(1, 31):\n",
    "        train_loss, valid_loss = [], []\n",
    "\n",
    "        net.train()  # 训练开始\n",
    "        for data, target in trainloader:\n",
    "            optimizer.zero_grad()  # 梯度置0\n",
    "            output = net(data)\n",
    "            loss = loss_function(output, target)  # 计算损失\n",
    "            loss.backward()   # 反向传播\n",
    "            optimizer.step()  # 更新参数\n",
    "            train_loss.append(loss.item())\n",
    "\n",
    "        net.eval()  # 验证开始\n",
    "        for data, target in validloader:\n",
    "            output = net(data)\n",
    "            loss = loss_function(output, target)\n",
    "            valid_loss.append(loss.item())\n",
    "\n",
    "        print(\"Epoch:{}, Training Loss:{}, Valid Loss:{}\".format(epoch, np.mean(train_loss), np.mean(valid_loss)))\n",
    "    print(\"======= Training Finished ! =========\")\n",
    "    \n",
    "    print(\"Testing Begining ... \")  # 模型测试\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for i, data_tuple in enumerate(testloader, 0):\n",
    "\n",
    "        data, labels = data_tuple\n",
    "        output = net(data)\n",
    "        _, preds_tensor = torch.max(output, 1)\n",
    "\n",
    "        total += labels.size(0)\n",
    "        correct += np.squeeze((preds_tensor == labels).sum().numpy())\n",
    "    print(\"Accuracy : {} %\".format(correct/total))"
   ]
  }
 ]
}