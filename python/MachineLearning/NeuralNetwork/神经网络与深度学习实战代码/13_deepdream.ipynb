{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "12-deepdream.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "NnDPLgSAzPDa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5426
        },
        "outputId": "e4e7c60d-7bb6-4f5a-b6dc-15afad59f722"
      },
      "cell_type": "code",
      "source": [
        "from keras.applications import inception_v3\n",
        "from keras import backend as K\n",
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "K.set_learning_phase(0)\n",
        "\n",
        "#加载inceptionV3网络\n",
        "model = inception_v3.InceptionV3(weights='imagenet', include_top = True)\n",
        "#将每层网络的名称打印出来，其中带有\"activation\"开头的网络层就是留有”残影“的卷积层\n",
        "for layer in model.layers:\n",
        "  print(layer.name)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "input_1\n",
            "conv2d_1\n",
            "batch_normalization_1\n",
            "activation_1\n",
            "conv2d_2\n",
            "batch_normalization_2\n",
            "activation_2\n",
            "conv2d_3\n",
            "batch_normalization_3\n",
            "activation_3\n",
            "max_pooling2d_1\n",
            "conv2d_4\n",
            "batch_normalization_4\n",
            "activation_4\n",
            "conv2d_5\n",
            "batch_normalization_5\n",
            "activation_5\n",
            "max_pooling2d_2\n",
            "conv2d_9\n",
            "batch_normalization_9\n",
            "activation_9\n",
            "conv2d_7\n",
            "conv2d_10\n",
            "batch_normalization_7\n",
            "batch_normalization_10\n",
            "activation_7\n",
            "activation_10\n",
            "average_pooling2d_1\n",
            "conv2d_6\n",
            "conv2d_8\n",
            "conv2d_11\n",
            "conv2d_12\n",
            "batch_normalization_6\n",
            "batch_normalization_8\n",
            "batch_normalization_11\n",
            "batch_normalization_12\n",
            "activation_6\n",
            "activation_8\n",
            "activation_11\n",
            "activation_12\n",
            "mixed0\n",
            "conv2d_16\n",
            "batch_normalization_16\n",
            "activation_16\n",
            "conv2d_14\n",
            "conv2d_17\n",
            "batch_normalization_14\n",
            "batch_normalization_17\n",
            "activation_14\n",
            "activation_17\n",
            "average_pooling2d_2\n",
            "conv2d_13\n",
            "conv2d_15\n",
            "conv2d_18\n",
            "conv2d_19\n",
            "batch_normalization_13\n",
            "batch_normalization_15\n",
            "batch_normalization_18\n",
            "batch_normalization_19\n",
            "activation_13\n",
            "activation_15\n",
            "activation_18\n",
            "activation_19\n",
            "mixed1\n",
            "conv2d_23\n",
            "batch_normalization_23\n",
            "activation_23\n",
            "conv2d_21\n",
            "conv2d_24\n",
            "batch_normalization_21\n",
            "batch_normalization_24\n",
            "activation_21\n",
            "activation_24\n",
            "average_pooling2d_3\n",
            "conv2d_20\n",
            "conv2d_22\n",
            "conv2d_25\n",
            "conv2d_26\n",
            "batch_normalization_20\n",
            "batch_normalization_22\n",
            "batch_normalization_25\n",
            "batch_normalization_26\n",
            "activation_20\n",
            "activation_22\n",
            "activation_25\n",
            "activation_26\n",
            "mixed2\n",
            "conv2d_28\n",
            "batch_normalization_28\n",
            "activation_28\n",
            "conv2d_29\n",
            "batch_normalization_29\n",
            "activation_29\n",
            "conv2d_27\n",
            "conv2d_30\n",
            "batch_normalization_27\n",
            "batch_normalization_30\n",
            "activation_27\n",
            "activation_30\n",
            "max_pooling2d_3\n",
            "mixed3\n",
            "conv2d_35\n",
            "batch_normalization_35\n",
            "activation_35\n",
            "conv2d_36\n",
            "batch_normalization_36\n",
            "activation_36\n",
            "conv2d_32\n",
            "conv2d_37\n",
            "batch_normalization_32\n",
            "batch_normalization_37\n",
            "activation_32\n",
            "activation_37\n",
            "conv2d_33\n",
            "conv2d_38\n",
            "batch_normalization_33\n",
            "batch_normalization_38\n",
            "activation_33\n",
            "activation_38\n",
            "average_pooling2d_4\n",
            "conv2d_31\n",
            "conv2d_34\n",
            "conv2d_39\n",
            "conv2d_40\n",
            "batch_normalization_31\n",
            "batch_normalization_34\n",
            "batch_normalization_39\n",
            "batch_normalization_40\n",
            "activation_31\n",
            "activation_34\n",
            "activation_39\n",
            "activation_40\n",
            "mixed4\n",
            "conv2d_45\n",
            "batch_normalization_45\n",
            "activation_45\n",
            "conv2d_46\n",
            "batch_normalization_46\n",
            "activation_46\n",
            "conv2d_42\n",
            "conv2d_47\n",
            "batch_normalization_42\n",
            "batch_normalization_47\n",
            "activation_42\n",
            "activation_47\n",
            "conv2d_43\n",
            "conv2d_48\n",
            "batch_normalization_43\n",
            "batch_normalization_48\n",
            "activation_43\n",
            "activation_48\n",
            "average_pooling2d_5\n",
            "conv2d_41\n",
            "conv2d_44\n",
            "conv2d_49\n",
            "conv2d_50\n",
            "batch_normalization_41\n",
            "batch_normalization_44\n",
            "batch_normalization_49\n",
            "batch_normalization_50\n",
            "activation_41\n",
            "activation_44\n",
            "activation_49\n",
            "activation_50\n",
            "mixed5\n",
            "conv2d_55\n",
            "batch_normalization_55\n",
            "activation_55\n",
            "conv2d_56\n",
            "batch_normalization_56\n",
            "activation_56\n",
            "conv2d_52\n",
            "conv2d_57\n",
            "batch_normalization_52\n",
            "batch_normalization_57\n",
            "activation_52\n",
            "activation_57\n",
            "conv2d_53\n",
            "conv2d_58\n",
            "batch_normalization_53\n",
            "batch_normalization_58\n",
            "activation_53\n",
            "activation_58\n",
            "average_pooling2d_6\n",
            "conv2d_51\n",
            "conv2d_54\n",
            "conv2d_59\n",
            "conv2d_60\n",
            "batch_normalization_51\n",
            "batch_normalization_54\n",
            "batch_normalization_59\n",
            "batch_normalization_60\n",
            "activation_51\n",
            "activation_54\n",
            "activation_59\n",
            "activation_60\n",
            "mixed6\n",
            "conv2d_65\n",
            "batch_normalization_65\n",
            "activation_65\n",
            "conv2d_66\n",
            "batch_normalization_66\n",
            "activation_66\n",
            "conv2d_62\n",
            "conv2d_67\n",
            "batch_normalization_62\n",
            "batch_normalization_67\n",
            "activation_62\n",
            "activation_67\n",
            "conv2d_63\n",
            "conv2d_68\n",
            "batch_normalization_63\n",
            "batch_normalization_68\n",
            "activation_63\n",
            "activation_68\n",
            "average_pooling2d_7\n",
            "conv2d_61\n",
            "conv2d_64\n",
            "conv2d_69\n",
            "conv2d_70\n",
            "batch_normalization_61\n",
            "batch_normalization_64\n",
            "batch_normalization_69\n",
            "batch_normalization_70\n",
            "activation_61\n",
            "activation_64\n",
            "activation_69\n",
            "activation_70\n",
            "mixed7\n",
            "conv2d_73\n",
            "batch_normalization_73\n",
            "activation_73\n",
            "conv2d_74\n",
            "batch_normalization_74\n",
            "activation_74\n",
            "conv2d_71\n",
            "conv2d_75\n",
            "batch_normalization_71\n",
            "batch_normalization_75\n",
            "activation_71\n",
            "activation_75\n",
            "conv2d_72\n",
            "conv2d_76\n",
            "batch_normalization_72\n",
            "batch_normalization_76\n",
            "activation_72\n",
            "activation_76\n",
            "max_pooling2d_4\n",
            "mixed8\n",
            "conv2d_81\n",
            "batch_normalization_81\n",
            "activation_81\n",
            "conv2d_78\n",
            "conv2d_82\n",
            "batch_normalization_78\n",
            "batch_normalization_82\n",
            "activation_78\n",
            "activation_82\n",
            "conv2d_79\n",
            "conv2d_80\n",
            "conv2d_83\n",
            "conv2d_84\n",
            "average_pooling2d_8\n",
            "conv2d_77\n",
            "batch_normalization_79\n",
            "batch_normalization_80\n",
            "batch_normalization_83\n",
            "batch_normalization_84\n",
            "conv2d_85\n",
            "batch_normalization_77\n",
            "activation_79\n",
            "activation_80\n",
            "activation_83\n",
            "activation_84\n",
            "batch_normalization_85\n",
            "activation_77\n",
            "mixed9_0\n",
            "concatenate_1\n",
            "activation_85\n",
            "mixed9\n",
            "conv2d_90\n",
            "batch_normalization_90\n",
            "activation_90\n",
            "conv2d_87\n",
            "conv2d_91\n",
            "batch_normalization_87\n",
            "batch_normalization_91\n",
            "activation_87\n",
            "activation_91\n",
            "conv2d_88\n",
            "conv2d_89\n",
            "conv2d_92\n",
            "conv2d_93\n",
            "average_pooling2d_9\n",
            "conv2d_86\n",
            "batch_normalization_88\n",
            "batch_normalization_89\n",
            "batch_normalization_92\n",
            "batch_normalization_93\n",
            "conv2d_94\n",
            "batch_normalization_86\n",
            "activation_88\n",
            "activation_89\n",
            "activation_92\n",
            "activation_93\n",
            "batch_normalization_94\n",
            "activation_86\n",
            "mixed9_1\n",
            "concatenate_2\n",
            "activation_94\n",
            "mixed10\n",
            "avg_pool\n",
            "predictions\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6zcyX_oH1J-T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "941b4c6e-a816-4307-bfb5-e8803a65b734"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "N8bBMPzszqHV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Model\n",
        "#把带有\"activation”的网络层全部抽取出来\n",
        "activation_layers = [layer.output for layer in model.layers if layer.name.startswith(\"activation_\")]\n",
        "activation_model = Model(model.input, outputs = activation_layers)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UxIrJWEj0efx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing import image\n",
        "\n",
        "#增加图片预处理代码，并把要使用的图片加载进来\n",
        "def  preprocess_image(image_path):\n",
        "  img = image.load_img(image_path)\n",
        "  img = image.img_to_array(img)\n",
        "  #将二维图片扩展到三维，最高维表示图片的数量，由于只有一张图片，因此最高维的数量设置为1\n",
        "  img = np.expand_dims(img, axis = 0)\n",
        "  img = inception_v3.preprocess_input(img)\n",
        "  return img\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bEFNYXcC2mcs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "layer_name = 'activation_41'\n",
        "#执行公式(1)获取给定卷积层的输出\n",
        "activation = model.get_layer(layer_name).output\n",
        "\n",
        "'''\n",
        "卷积层的输出是个多维向量，我们如何让一个多维向量增大呢？一个办法是求多维向量里面每个分量的平方和，\n",
        "然后我们调整图片像素使得该平方和增大\n",
        "'''\n",
        "scaling = K.prod(K.cast(K.shape(activation), 'float32'))\n",
        "'''\n",
        "计算时我们要忽略图片边缘点,下面代码中第一个2:-2中，2表示忽略左边缘前2个像素点，-2表示忽略右边缘最后2个像素点。\n",
        "第二个2：-2中，2表示忽略顶部头2个像素点，-2表示忽略忽略底部倒数2个像素点\n",
        "'''\n",
        "#loss对应函数（1）\n",
        "loss = K.sum(K.square(activation[:, 2:-1, 2:-2, :])) / scaling\n",
        "\n",
        "#对像素点求偏导数，对应函数（2）\n",
        "dream = model.input\n",
        "grads = K.gradients(loss, dream)[0]\n",
        "#将偏导数转换为[0,1]之间的值\n",
        "grads /= K.maximum(K.mean(K.abs(grads)), 1e-7)\n",
        "\n",
        "iterate_grad_ac_step = K.function([dream], [loss, grads])\n",
        "\n",
        "#使用梯度上升发调整输入图片像素点\n",
        "def  gradient_ascent(x, iterations, step, max_loss = None):\n",
        "  for i in range(iterations):\n",
        "    loss_value, grad_values = iterate_grad_ac_step([x])\n",
        "    print('Loss value is at ', i, ':', loss_value)\n",
        "    '''\n",
        "    限制增大上限，如果卷积层输出过大，那有可能是输入图片像素点调整过头，这会\n",
        "    导致图片视觉效果不好看\n",
        "    '''\n",
        "    if max_loss is not None and loss_value > max_loss:\n",
        "      break\n",
        "    x += step * grad_values\n",
        "  return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NSHO9Ur--Yjn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import scipy\n",
        "\n",
        "def deprocess_image(x):\n",
        "  if K.image_data_format() == 'channels_first':\n",
        "    '''\n",
        "    x格式为(1, 3, width, height), 其中3表示像素点RGB的值，我们需要把前面多余的1去掉，\n",
        "    然后把格式转换为(width, height, 3)\n",
        "    '''\n",
        "    #去掉最高维度多余的1\n",
        "    x = x.reshape((3, x.shape[2], x.shape[3]))\n",
        "    #转换为（width, height, RGB)\n",
        "    x = x.transpose((1, 2, 0))\n",
        "  else:\n",
        "    '''\n",
        "    如果x的格式为(1, width, height, 3),那么我们去掉最高维度多余的1即可\n",
        "    '''\n",
        "    x = x.reshape((x.shape[1], x.shape[2], 3))\n",
        "    \n",
        "  '''\n",
        "  图片在输入inceptionV3进行处理时，它会对图片像素点做如下变换：\n",
        "  x /= 255.\n",
        "  x -= 0.5\n",
        "  x *= 2.\n",
        "  因此我们要对它的输出做对应的反变换才能正常显示图片\n",
        "  '''\n",
        "  x /= 2.\n",
        "  x += .5\n",
        "  x *= 255.\n",
        "  \n",
        "  x = np.clip(x, 0, 255).astype('uint8')\n",
        "  return x\n",
        "\n",
        "def  resize_img(img, size):\n",
        "  #将图片根据给定比例进行缩放\n",
        "  img = np.copy(img)\n",
        "  factors = (1, float(size[0]) / img.shape[1],\n",
        "                float(size[1]) / img.shape[2],\n",
        "             1\n",
        "            )\n",
        "  return scipy.ndimage.zoom(img, factors, order = 1)\n",
        "\n",
        "def  save_img(img, fname):\n",
        "  img = deprocess_image(np.copy(img))\n",
        "  scipy.misc.imsave('/content/gdrive/My Drive/' + fname, img)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Q7ZTmQn_Ga-K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f928460a-0e8d-4f1f-b907-f2115c05a9d0"
      },
      "cell_type": "code",
      "source": [
        "#将图片缩小4次\n",
        "num_octave = 4\n",
        "#缩小比例为1.4\n",
        "octave_scale = 1.4\n",
        "\n",
        "image_path = '/content/gdrive/My Drive/blue_sky.jpg'\n",
        "img = preprocess_image(image_path)\n",
        "print(img.shape)\n",
        "\n",
        "original_shape = img.shape[1:3]\n",
        "successive_shapes = [original_shape]\n",
        "#将图片以比例1.4连续缩小\n",
        "for i in range(1, num_octave):\n",
        "  shape = tuple([int(dim / (octave_scale ** i)) for dim in original_shape])\n",
        "  successive_shapes.append(shape)\n",
        "  \n",
        "                        \n",
        "successive_shapes = successive_shapes[::-1]\n",
        "original_img = np.copy(img)\n",
        "#将图片缩小到最小形态\n",
        "shrunk_original_img = resize_img(img, successive_shapes[0])\n",
        "print(successive_shapes)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 386, 580, 3)\n",
            "[(140, 211), (196, 295), (275, 414), (386, 580)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YO8esGmWJOET",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1496
        },
        "outputId": "aa8a3e5f-0f93-4f22-e0bc-c8e354eb755a"
      },
      "cell_type": "code",
      "source": [
        "MAX_ITERATION = 20\n",
        "MAX_LOSS = 20\n",
        "learning_rate = 0.01\n",
        "\n",
        "for shape in successive_shapes:\n",
        "  print('Processing image shape: ', shape)\n",
        "  #将上一步梯度上升法调整后的图片以1.4比例放大\n",
        "  img = resize_img(img, shape)\n",
        " \n",
        "  '''\n",
        "  将图片缩小1.4倍，然后再放大1.4倍，一来一回会造成像素点信息损失，下面三行代码将损失记录下来\n",
        "  '''\n",
        "  upscaled_shrunk_original_img = resize_img(shrunk_original_img, shape)\n",
        "  same_size_original = resize_img(original_img, shape)\n",
        "  lost_detail = same_size_original - upscaled_shrunk_original_img\n",
        "  #下面代码相当于执行图12-60中加号对应操作\n",
        "  img += lost_detail\n",
        "  \n",
        "   #使用梯度上升法取得每个像素点的调整幅度\n",
        "  img = gradient_ascent(img, iterations = MAX_ITERATION,\n",
        "                       step = learning_rate,\n",
        "                       max_loss = MAX_LOSS)\n",
        "  \n",
        "  shrunk_original_img = resize_img(original_img, shape)\n",
        "  save_img(img, fname='dream_at_scale_' + str(shape) + '.png')\n",
        "  \n",
        "save_img(img, fname='final_dream.png')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing image shape:  (140, 211)\n",
            "Loss value is at  0 : 0.17687777\n",
            "Loss value is at  1 : 0.3071308\n",
            "Loss value is at  2 : 0.4573659\n",
            "Loss value is at  3 : 0.6172608\n",
            "Loss value is at  4 : 0.78259045\n",
            "Loss value is at  5 : 0.9258283\n",
            "Loss value is at  6 : 1.0947613\n",
            "Loss value is at  7 : 1.2477114\n",
            "Loss value is at  8 : 1.4072728\n",
            "Loss value is at  9 : 1.5584034\n",
            "Loss value is at  10 : 1.7039208\n",
            "Loss value is at  11 : 1.853727\n",
            "Loss value is at  12 : 1.9702474\n",
            "Loss value is at  13 : 2.0778344\n",
            "Loss value is at  14 : 2.1962552\n",
            "Loss value is at  15 : 2.3339348\n",
            "Loss value is at  16 : 2.4356647\n",
            "Loss value is at  17 : 2.5728376\n",
            "Loss value is at  18 : 2.6820874\n",
            "Loss value is at  19 : 2.7637002\n",
            "Processing image shape:  (196, 295)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:44: DeprecationWarning: `imsave` is deprecated!\n",
            "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
            "Use ``imageio.imwrite`` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss value is at  0 : 0.4048001\n",
            "Loss value is at  1 : 0.71947783\n",
            "Loss value is at  2 : 0.9570125\n",
            "Loss value is at  3 : 1.1783383\n",
            "Loss value is at  4 : 1.3832954\n",
            "Loss value is at  5 : 1.5628526\n",
            "Loss value is at  6 : 1.7058357\n",
            "Loss value is at  7 : 1.8806349\n",
            "Loss value is at  8 : 2.0349624\n",
            "Loss value is at  9 : 2.1661477\n",
            "Loss value is at  10 : 2.3290172\n",
            "Loss value is at  11 : 2.4676006\n",
            "Loss value is at  12 : 2.5842729\n",
            "Loss value is at  13 : 2.695279\n",
            "Loss value is at  14 : 2.841451\n",
            "Loss value is at  15 : 2.9296634\n",
            "Loss value is at  16 : 3.0645425\n",
            "Loss value is at  17 : 3.1719193\n",
            "Loss value is at  18 : 3.285319\n",
            "Loss value is at  19 : 3.3802764\n",
            "Processing image shape:  (275, 414)\n",
            "Loss value is at  0 : 0.46704948\n",
            "Loss value is at  1 : 0.80155885\n",
            "Loss value is at  2 : 1.0665408\n",
            "Loss value is at  3 : 1.2956998\n",
            "Loss value is at  4 : 1.4996808\n",
            "Loss value is at  5 : 1.7121378\n",
            "Loss value is at  6 : 1.8910944\n",
            "Loss value is at  7 : 2.0419438\n",
            "Loss value is at  8 : 2.2079356\n",
            "Loss value is at  9 : 2.3601115\n",
            "Loss value is at  10 : 2.503827\n",
            "Loss value is at  11 : 2.6327841\n",
            "Loss value is at  12 : 2.7630935\n",
            "Loss value is at  13 : 2.875832\n",
            "Loss value is at  14 : 3.0223475\n",
            "Loss value is at  15 : 3.1266437\n",
            "Loss value is at  16 : 3.2513173\n",
            "Loss value is at  17 : 3.3542545\n",
            "Loss value is at  18 : 3.4817092\n",
            "Loss value is at  19 : 3.5624702\n",
            "Processing image shape:  (386, 580)\n",
            "Loss value is at  0 : 0.55502504\n",
            "Loss value is at  1 : 0.90124935\n",
            "Loss value is at  2 : 1.184409\n",
            "Loss value is at  3 : 1.4028296\n",
            "Loss value is at  4 : 1.6181362\n",
            "Loss value is at  5 : 1.8162687\n",
            "Loss value is at  6 : 1.9966216\n",
            "Loss value is at  7 : 2.1777978\n",
            "Loss value is at  8 : 2.3360188\n",
            "Loss value is at  9 : 2.483855\n",
            "Loss value is at  10 : 2.652875\n",
            "Loss value is at  11 : 2.7909307\n",
            "Loss value is at  12 : 2.9349926\n",
            "Loss value is at  13 : 3.0655732\n",
            "Loss value is at  14 : 3.1903636\n",
            "Loss value is at  15 : 3.3187866\n",
            "Loss value is at  16 : 3.4442227\n",
            "Loss value is at  17 : 3.5684154\n",
            "Loss value is at  18 : 3.6761208\n",
            "Loss value is at  19 : 3.7982085\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}